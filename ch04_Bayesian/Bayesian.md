机器学习中的朴素贝叶斯算法就是基于贝叶斯定理来做分类。贝叶斯定理是一个已经有300年历史的古老定理。其推导过程这里就不去重复了，大家可以自己学习。

### 一、概念解释
 
我们先来熟悉几个概念


联合概率：包含多个条件，所有条件同时成立的概率，记为P(A,B)或者P(A∩B)，也就是A和B同时发生的概率

条件概率（又叫似然概率）：事件B发生的条件下事件A发生的概率，记作P(A|B)；多个条件事件的时候，各个事件的条件需要相互独立，特性P(A1,A2|B)=P(A1|B)P(A2|B)，此概率公式成立的条件是A1,A2是互相独立的。

先验概率：单独事件发生的概率，如 P(A)、P(B)。是指根据以往经验和分析得到的概率，常见的是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。

后验概率：若 P(X|Y) 为正向，则 P(Y|X) 为反向，基于先验概率求得的反向条件概率，形式上与条件概率相同

 
### 二、公式介绍

贝叶斯公式：  
![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/0.png?raw=true)

这里：

P(A|B)是后验概率，一般是我们求解的目标。

P(B|A)是条件概率，又叫似然概率，一般是通过历史数据统计得到。一般不把它叫做先验概率，但从定义上也符合先验定义。

P(A)是先验概率，一般都是人主观给出的。贝叶斯中的先验概率一般特指它。

P(B)也是先验概率，只是在贝叶斯的很多应用中不重要（因为只要最大后验不求绝对值），需要时往往用全概率公式计算得到。

所以总的来说P(B|A)、P(A)、P(B)都可以视作先验概率，也就是可以通过历史数据统计得到，这样就为我们求解P(A|B)提供了基础。

此外机器学习中贝叶斯算法之所以在前面加个“朴素”就在于假设属性之间的相互独立性，属性相关性较大的话分类效果会打折扣。

 
### 三、基础例子
这个理解起来实在晦涩，还是先来看两个例子吧

一口袋里有3只红球、2只白球，采用不放回方式摸取，求：  
⑴. 第一次摸到红球（记作A）的概率；  
⑵. 第二次摸到红球（记作B）的概率；  
⑶. 已知第二次摸到了红球，求第一次摸到的是红球的概率。  
解：  
⑴. P(A)=3/5，这就是先验概率；  
⑵. P(B)=P(A)P(B|A)+P(A逆)P(B|A逆)=3/5；  
⑶. P(A|B)=P(A)P(B|A)/P(B)=1/2，这就是后验概率。  

 
### 四、实际例子
似乎还是有点难懂，再来继续看一个复杂点的朴素贝叶斯分类应用。已知有如下的天气记录与是否打网球的关系记录表。  
![Alt text](https://github.com/Miraclelucy/ml_in_action/blob/main/img/1.png?raw=true)

假设今天天气状况是：天气晴、气温冷、湿度高、风力强，问是否会去打网球呢？

现在要计算P(打网球|天气晴、气温冷、湿度高、风力强)和P(不打网球|天气晴、气温冷、湿度高、风力强)的概率。根据贝叶斯公式（假设，天气、气温、湿度和风力是相互独立的）  
![Alt text](https://github.com/Miraclelucy/ml_in_action/blob/main/img/2.png?raw=true)

从前面提供的统计数据可以计算出

P(天气晴|打网球)=2/9

P(气温冷|打网球)=3/9

P(湿度高|打网球)=3/9

P(风力强|打网球)=3/9

P(打网球)=9/14

P(天气晴)=5/14

P(气温冷)=4/14

P(湿度高)=7/14

P(风力强)=6/14

从而计算得到  
![Alt text](https://github.com/Miraclelucy/ml_in_action/blob/main/img/3.png?raw=true)

同理可以计算出  
![Alt text](https://github.com/Miraclelucy/ml_in_action/blob/main/img/4.png?raw=true)

很显然不打网球的概率高于打网球的概率，所以结论是不打网球。

 

看完这两个例子，是不是开始有点感觉了。

 

### 五、scikit-learn 实现的朴素贝叶斯分类器

根据数据特征的分布情况，scikit-learn 实现了三种朴素贝叶斯分类器：

1.   GaussianNB，用于任意连续数据，数据呈高斯分布。会保存每个类别中每个特征的平均值和标准差；

2.   BernoulliNB，假定输入数据为二分类数据，数据呈伯努利分布。计算每个类别中的非零元素个数

3.   MultinomialNB，假定输入数据为计数数据（即每个特征代表某个对象的整数计数，比如一个单词在句子里出现的次数），数据呈多项式分布。计算每个类别中每个特征的平均值

GaussianNB 主要用于高维数据，BernoulliNB 和 MultinomialNB 广泛用于稀疏计数数据，比如文本。MultinomialNB 的性能通常要优于 BernoulliNB ，特别是包含很多非零特征的数据集（即大型文档）。



### 六、算法示例

垃圾邮件分类，spam文件夹是垃圾邮件，ham文件夹是正常邮件，test文件夹里的文件以spam或ham标定了其期望标签，可以与实际预测结果做对比。本算法涉及到jieba分词，需要安装jieba库，大家可以自行搜索安装，同时也用到停用词库，可以使用附件提供的，也可以自定义
