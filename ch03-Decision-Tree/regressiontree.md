### 1、什么是决策树

所谓决策树，就是一个类似于流程图的树形结构，树的每一个节点代表的是对一个特征的测试，树的分支代表该特征的每一个测试结果，而树的每一个叶子节点代表一个评判类别。内部节点用椭圆表示，叶子节点用矩形表示。机器学习中决策树根据现有数据，选择合适特征构建决策树，之后既可以利用这棵树来执行预测。

以上一讲朴素贝叶斯里的的是否打羽毛球的数据为例，来看看决策树是怎么工作的  
![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/ch04/1.PNG?raw=true)

如果我们以前面的条件有节点画一棵树就是这个样子：  
![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/ch03/3.png?raw=true)

也可能画成这个样子：  
![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/ch03/4.png?raw=true)

这是不是就跟条件判断很相似？决策树嘛，就是每到节点分叉的时候以一定的依据（特征）做一次测试（决策），这不就是if…then…吗。

而且同样的样本集，可以画出很多不同的决策树，有的决策树简单有的决策树复杂，这其中的奥妙是什么呢？这就涉及到关键的决策树生成了。



### 2、决策树生成

特征选择是决策树生成的关键，特征选择就是从训练数据的众多的特征中选择一个特征作为当前节点分叉的标准。如何选择特征有很多不同量化评估标准，从而衍生出不同的决策树算法, 如ID3（通过信息增益选择特征）、C4.5（通过信息增益比选择特征）、CART（通过Gini指数选择特征）等。

这里来看看以信息增益选择特征的ID3算法。信息增益又是个什么东东呢？信息增益是信息熵和条件熵的差，通俗来说就是在划分数据集之前和之后信息发生的变化。通过计算每个特征值划分数据集获得的信息增益，信息增益最高的特征就会作为当前分叉节点最好的选择。

信息增益计算的方法如下：

![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/ch03/1.png?raw=true)

当熵和条件熵中的概率由统计数据得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵。

信息增益表示由于已知特征Y的信息后，数据集X的分类不确定性减少的程度，定义为：

Gain(X,Y) = H(X) – H(X|Y)

即集合X的经验熵H(X)与特征Y条件下X的经验条件熵H(X|Y)之差。

选取信息增益最大的特征来分叉就会使数据集在分类后不确定性减少程度最大，也就是数据集的不确定性更小了，这正是我们所期望的。

![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/ch03/2.png?raw=true)

很明显，天气的信息增益最大，所以选择天气为树的根节点。

下一级的分支节点特征选取采用相同的计算方法，直到分类完成，这样最终画出来的是图一的树。

### 3、剪枝

决策树过拟合的可能性非常大，一组数据理论上一定是可以完全分开的，大不了一个叶子节点就一个数据，不就分开了吗，但是这样的树，在训练集上面表现的效果当然很好，但在测试集上面的表现会很差，泛化能力很弱。

所以就要对决策树进行剪枝，一般有前剪枝和后剪枝。比较常用的前剪枝，通过限制叶子节点个数、树的深度、信息增益量等方式来实现，或者也不一定非要选择数据集的所有特征，选择一部分特征也是剪枝。



### 4、回归决策树

前面讲的都是决策树用于分类，称为分类决策树，简称分类树。决策树还可以用于回归，称为回归决策树，简称回归树。

与分类树不同的是，回归树会遍历所有输入变量，找到最优的切分变量x和最优的切分点y，输入空间划分为两部分，然后重复这个操作。而如何找到最优的x和y是通过比较不同划分的误差来得到的。一个输入空间的划分的误差是用真实值和划分区域的预测值的偏差（如均方差MSE，平均绝对误差MAE等）来衡量的。

总的来说，回归树就是将特征空间划分成若干单元，每一个划分单元对应有一个特定的输出。因为每个结点都是“是”和“否”的判断，所以划分的边界是平行于坐标轴的。对于测试数据，我们只要按照特征将其归到某个单元，便得到对应的输出值。

下图展示了最大深度为1和3的两条回归树曲线和一条线性回归拟合曲线的对比。我们后续会探讨线性回归拟合算法。
![avatar](https://github.com/Miraclelucy/ml_in_action/blob/main/img/ch03/5.png?raw=true)

### 5、上代码

